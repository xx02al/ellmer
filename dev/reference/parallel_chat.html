<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Submit multiple chats in parallel — parallel_chat • ellmer</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_Pro-0.4.10/font.css" rel="stylesheet"><link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Submit multiple chats in parallel — parallel_chat"><meta name="description" content="
If you have multiple prompts, you can submit them in parallel. This is
typically considerably faster than submitting them in sequence, especially
with Gemini and OpenAI.
If you're using chat_openai() or chat_anthropic() and you're willing
to wait longer, you might want to use batch_chat() instead, as it comes
with a 50% discount in return for taking up to 24 hours."><meta property="og:description" content="
If you have multiple prompts, you can submit them in parallel. This is
typically considerably faster than submitting them in sequence, especially
with Gemini and OpenAI.
If you're using chat_openai() or chat_anthropic() and you're willing
to wait longer, you might want to use batch_chat() instead, as it comes
with a 50% discount in return for taking up to 24 hours."><meta property="og:image" content="https://ellmer.tidyverse.org/logo.png"><meta name="robots" content="noindex"><script defer data-domain="ellmer.tidyverse.org,all.tidyverse.org" src="https://plausible.io/js/plausible.js"></script></head><body>
    <a href="#container" class="visually-hidden-focusable">Skip to content</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-none" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ellmer</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.3.2.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/ellmer.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/programming.html">Programming with ellmer</a></li>
    <li><a class="dropdown-item" href="../articles/prompt-design.html">Prompt design</a></li>
    <li><a class="dropdown-item" href="../articles/streaming-async.html">Streaming and async APIs</a></li>
    <li><a class="dropdown-item" href="../articles/structured-data.html">Structured data</a></li>
    <li><a class="dropdown-item" href="../articles/tool-calling.html">Tool/function calling</a></li>
  </ul></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-news" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">News</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-news"><li><h6 class="dropdown-header" data-toc-skip>Releases</h6></li>
    <li><a class="external-link dropdown-item" href="https://www.tidyverse.org/blog/2025/07/ellmer-0-3-0/">Version 0.3.0</a></li>
    <li><a class="external-link dropdown-item" href="https://www.tidyverse.org/blog/2025/05/ellmer-0-2-0/">Version 0.2.0</a></li>
    <li><a class="external-link dropdown-item" href="https://posit.co/blog/announcing-ellmer/">Version 0.1.0</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../news/index.html">Changelog</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tidyverse/ellmer/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic" id="container">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Submit multiple chats in parallel</h1>
      <small class="dont-index">Source: <a href="https://github.com/tidyverse/ellmer/blob/main/R/parallel-chat.R" class="external-link"><code>R/parallel-chat.R</code></a></small>
      <div class="d-none name"><code>parallel_chat.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental" class="external-link"><img src="figures/lifecycle-experimental.svg" alt="[Experimental]"></a></p>
<p>If you have multiple prompts, you can submit them in parallel. This is
typically considerably faster than submitting them in sequence, especially
with Gemini and OpenAI.</p>
<p>If you're using <code><a href="chat_openai.html">chat_openai()</a></code> or <code><a href="chat_anthropic.html">chat_anthropic()</a></code> and you're willing
to wait longer, you might want to use <code><a href="batch_chat.html">batch_chat()</a></code> instead, as it comes
with a 50% discount in return for taking up to 24 hours.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">parallel_chat</span><span class="op">(</span><span class="va">chat</span>, <span class="va">prompts</span>, max_active <span class="op">=</span> <span class="fl">10</span>, rpm <span class="op">=</span> <span class="fl">500</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">parallel_chat_text</span><span class="op">(</span><span class="va">chat</span>, <span class="va">prompts</span>, max_active <span class="op">=</span> <span class="fl">10</span>, rpm <span class="op">=</span> <span class="fl">500</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">parallel_chat_structured</span><span class="op">(</span></span>
<span>  <span class="va">chat</span>,</span>
<span>  <span class="va">prompts</span>,</span>
<span>  <span class="va">type</span>,</span>
<span>  convert <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  include_tokens <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  include_cost <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  max_active <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  rpm <span class="op">=</span> <span class="fl">500</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-chat">chat<a class="anchor" aria-label="anchor" href="#arg-chat"></a></dt>
<dd><p>A base chat object.</p></dd>


<dt id="arg-prompts">prompts<a class="anchor" aria-label="anchor" href="#arg-prompts"></a></dt>
<dd><p>A vector created by <code><a href="interpolate.html">interpolate()</a></code> or a list
of character vectors.</p></dd>


<dt id="arg-max-active">max_active<a class="anchor" aria-label="anchor" href="#arg-max-active"></a></dt>
<dd><p>The maximum number of simultaneous requests to send.</p>
<p>For <code><a href="chat_anthropic.html">chat_anthropic()</a></code>, note that the number of active connections is
limited primarily by the output tokens per minute limit (OTPM) which is
estimated from the <code>max_tokens</code> parameter, which defaults to 4096. That
means if your usage tier limits you to 16,000 OTPM, you should either set
<code>max_active = 4</code> (16,000 / 4096) to decrease the number of active
connections or use <code><a href="params.html">params()</a></code> in <code><a href="chat_anthropic.html">chat_anthropic()</a></code> to decrease
<code>max_tokens</code>.</p></dd>


<dt id="arg-rpm">rpm<a class="anchor" aria-label="anchor" href="#arg-rpm"></a></dt>
<dd><p>Maximum number of requests per minute.</p></dd>


<dt id="arg-type">type<a class="anchor" aria-label="anchor" href="#arg-type"></a></dt>
<dd><p>A type specification for the extracted data. Should be
created with a <code><a href="type_boolean.html">type_()</a></code> function.</p></dd>


<dt id="arg-convert">convert<a class="anchor" aria-label="anchor" href="#arg-convert"></a></dt>
<dd><p>If <code>TRUE</code>, automatically convert from JSON lists to R
data types using the schema. This typically works best when <code>type</code> is
<code><a href="type_boolean.html">type_object()</a></code> as this will give you a data frame with one column for
each property. If <code>FALSE</code>, returns a list.</p></dd>


<dt id="arg-include-tokens">include_tokens<a class="anchor" aria-label="anchor" href="#arg-include-tokens"></a></dt>
<dd><p>If <code>TRUE</code>, and the result is a data frame, will
add <code>input_tokens</code> and <code>output_tokens</code> columns giving the total input
and output tokens for each prompt.</p></dd>


<dt id="arg-include-cost">include_cost<a class="anchor" aria-label="anchor" href="#arg-include-cost"></a></dt>
<dd><p>If <code>TRUE</code>, and the result is a data frame, will
add <code>cost</code> column giving the cost of each prompt.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>For <code>parallel_chat()</code>, a list of <a href="Chat.html">Chat</a> objects, one for each prompt.
For <code>parallel_chat_text()</code>, a character vector of text responses.
For <code>parallel_chat_structured()</code>, a single structured data object with one
element for each prompt. Typically, when <code>type</code> is an object, this will
will be a data frame with one row for each prompt, and one column for each
property.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">chat</span> <span class="op">&lt;-</span> <span class="fu"><a href="chat_openai.html">chat_openai</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Using <span style="color: #00BB00;">model</span> = <span style="color: #0000BB;">"gpt-4.1"</span>.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Chat ----------------------------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="va">country</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Canada"</span>, <span class="st">"New Zealand"</span>, <span class="st">"Jamaica"</span>, <span class="st">"United States"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">prompts</span> <span class="op">&lt;-</span> <span class="fu"><a href="interpolate.html">interpolate</a></span><span class="op">(</span><span class="st">"What's the capital of {{country}}?"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">parallel_chat</span><span class="op">(</span><span class="va">chat</span>, <span class="va">prompts</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[1]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> &lt;Chat OpenAI/gpt-4.1 turns=2 tokens=13/10 $0.00&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #0000BB;">user</span> [13] ──────────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> What's the capital of Canada?</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #00BB00;">assistant</span> [10] ─────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The capital of Canada is **Ottawa**.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[2]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> &lt;Chat OpenAI/gpt-4.1 turns=2 tokens=14/11 $0.00&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #0000BB;">user</span> [14] ──────────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> What's the capital of New Zealand?</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #00BB00;">assistant</span> [11] ─────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The capital of New Zealand is **Wellington**.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[3]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> &lt;Chat OpenAI/gpt-4.1 turns=2 tokens=13/10 $0.00&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #0000BB;">user</span> [13] ──────────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> What's the capital of Jamaica?</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #00BB00;">assistant</span> [10] ─────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The capital of Jamaica is **Kingston**.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [[4]]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> &lt;Chat OpenAI/gpt-4.1 turns=2 tokens=14/12 $0.00&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #0000BB;">user</span> [14] ──────────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> What's the capital of United States?</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ── <span style="color: #00BB00;">assistant</span> [12] ─────────────────────────────────────────────────────</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> The capital of the United States is Washington, D.C.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Structured data -----------------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="va">prompts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="st">"I go by Alex. 42 years on this planet and counting."</span>,</span></span>
<span class="r-in"><span>  <span class="st">"Pleased to meet you! I'm Jamal, age 27."</span>,</span></span>
<span class="r-in"><span>  <span class="st">"They call me Li Wei. Nineteen years young."</span>,</span></span>
<span class="r-in"><span>  <span class="st">"Fatima here. Just celebrated my 35th birthday last week."</span>,</span></span>
<span class="r-in"><span>  <span class="st">"The name's Robert - 51 years old and proud of it."</span>,</span></span>
<span class="r-in"><span>  <span class="st">"Kwame here - just hit the big 5-0 this year."</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">type_person</span> <span class="op">&lt;-</span> <span class="fu"><a href="type_boolean.html">type_object</a></span><span class="op">(</span>name <span class="op">=</span> <span class="fu"><a href="type_boolean.html">type_string</a></span><span class="op">(</span><span class="op">)</span>, age <span class="op">=</span> <span class="fu"><a href="type_boolean.html">type_number</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">parallel_chat_structured</span><span class="op">(</span><span class="va">chat</span>, <span class="va">prompts</span>, <span class="va">type_person</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     name age</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1   Alex  42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2  Jamal  27</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3 Li Wei  19</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4 Fatima  35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5 Robert  51</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6  Kwame  50</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


   </div>
  <footer><div class="container">
  <div class="pkgdown-footer-left">
  <p>Developed by <a href="https://hadley.nz" class="external-link">Hadley Wickham</a>, Joe Cheng, Aaron Jacobs, <a href="https://garrickadenbuie.com" class="external-link">Garrick Aden-Buie</a>, <a href="http://schloerke.com" class="external-link">Barret Schloerke</a>, <a href="https://www.posit.co" class="external-link"><img src="https://www.tidyverse.org/posit-logo.svg" alt="Posit" height="16" width="62" style="margin-bottom: 3px;"></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

  </div></footer></body></html>


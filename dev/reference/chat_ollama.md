# Chat with a local Ollama model

To use `chat_ollama()` first download and install
[Ollama](https://ollama.com). Then install some models either from the
command line (e.g. with `ollama pull llama3.1`) or within R using
[ollamar](https://hauselin.github.io/ollama-r/) (e.g.
`ollamar::pull("llama3.1")`).

Built on top of
[`chat_openai_compatible()`](https://ellmer.tidyverse.org/dev/reference/chat_openai_compatible.md).

### Known limitations

- Tool calling is not supported with streaming (i.e. when `echo` is
  `"text"` or `"all"`)

- Models can only use 2048 input tokens, and there's no way to get them
  to use more, except by creating a custom model with a different
  default.

- Tool calling generally seems quite weak, at least with the models I
  have tried it with.

## Usage

``` r
chat_ollama(
  system_prompt = NULL,
  base_url = Sys.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
  model,
  params = NULL,
  api_args = list(),
  echo = NULL,
  api_key = NULL,
  credentials = NULL,
  api_headers = character()
)

models_ollama(base_url = "http://localhost:11434", credentials = NULL)
```

## Arguments

- system_prompt:

  A system prompt to set the behavior of the assistant.

- base_url:

  The base URL to the endpoint; the default is OpenAI's public API.

- model:

  The model to use for the chat. Use `models_ollama()` to see all
  options.

- params:

  Common model parameters, usually created by
  [`params()`](https://ellmer.tidyverse.org/dev/reference/params.md).

- api_args:

  Named list of arbitrary extra arguments appended to the body of every
  chat API call. Combined with the body object generated by ellmer with
  [`modifyList()`](https://rdrr.io/r/utils/modifyList.html).

- echo:

  One of the following options:

  - `none`: don't emit any output (default when running in a function).

  - `output`: echo text and tool-calling output as it streams in
    (default when running at the console).

  - `all`: echo all input and output.

  Note this only affects the
  [`chat()`](https://ellmer.tidyverse.org/dev/reference/chat-any.md)
  method.

- api_key:

  **\[deprecated\]** Use `credentials` instead.

- credentials:

  Ollama doesn't require credentials for local usage and in most cases
  you do not need to provide `credentials`.

  However, if you're accessing an Ollama instance hosted behind a
  reverse proxy or secured endpoint that enforces bearer‚Äêtoken
  authentication, you can set the `OLLAMA_API_KEY` environment variable
  or provide a callback function to `credentials`.

- api_headers:

  Named character vector of arbitrary extra headers appended to every
  chat API call.

## Value

A [Chat](https://ellmer.tidyverse.org/dev/reference/Chat.md) object.

## See also

Other chatbots:
[`chat_anthropic()`](https://ellmer.tidyverse.org/dev/reference/chat_anthropic.md),
[`chat_aws_bedrock()`](https://ellmer.tidyverse.org/dev/reference/chat_aws_bedrock.md),
[`chat_azure_openai()`](https://ellmer.tidyverse.org/dev/reference/chat_azure_openai.md),
[`chat_cloudflare()`](https://ellmer.tidyverse.org/dev/reference/chat_cloudflare.md),
[`chat_databricks()`](https://ellmer.tidyverse.org/dev/reference/chat_databricks.md),
[`chat_deepseek()`](https://ellmer.tidyverse.org/dev/reference/chat_deepseek.md),
[`chat_github()`](https://ellmer.tidyverse.org/dev/reference/chat_github.md),
[`chat_google_gemini()`](https://ellmer.tidyverse.org/dev/reference/chat_google_gemini.md),
[`chat_groq()`](https://ellmer.tidyverse.org/dev/reference/chat_groq.md),
[`chat_huggingface()`](https://ellmer.tidyverse.org/dev/reference/chat_huggingface.md),
[`chat_mistral()`](https://ellmer.tidyverse.org/dev/reference/chat_mistral.md),
[`chat_openai()`](https://ellmer.tidyverse.org/dev/reference/chat_openai.md),
[`chat_openai_compatible()`](https://ellmer.tidyverse.org/dev/reference/chat_openai_compatible.md),
[`chat_openrouter()`](https://ellmer.tidyverse.org/dev/reference/chat_openrouter.md),
[`chat_perplexity()`](https://ellmer.tidyverse.org/dev/reference/chat_perplexity.md),
[`chat_portkey()`](https://ellmer.tidyverse.org/dev/reference/chat_portkey.md)

## Examples

``` r
if (FALSE) { # \dontrun{
chat <- chat_ollama(model = "llama3.2")
chat$chat("Tell me three jokes about statisticians")
} # }
```
